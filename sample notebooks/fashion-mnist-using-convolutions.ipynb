{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# The **Fashion-MNIST** clothing classification problem is a new standard dataset used in computer vision and deep learning.\n\nIt is a dataset comprised of 60,000 small square 28×28 pixel grayscale images of items of 10 types of clothing, such as shoes, t-shirts, dresses, and more. The mapping of all 0-9 integers to class labels is listed below.\n\n![](https://image.itmedia.co.jp/ait/articles/2005/28/cover_news016.png)\n\nIt is a more challenging classification problem than MNIST and top results are achieved by deep learning convolutional neural networks with a classification accuracy of about 90% to 95% on the hold out test dataset.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport keras\nfrom keras.models import Sequential\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten\nfrom tensorflow.keras.optimizers import Adam\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-02T08:39:34.656283Z","iopub.execute_input":"2021-11-02T08:39:34.656657Z","iopub.status.idle":"2021-11-02T08:39:34.666628Z","shell.execute_reply.started":"2021-11-02T08:39:34.656624Z","shell.execute_reply":"2021-11-02T08:39:34.665405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Dataset\n\nThe images are all pre-segmented, that the images all have the same square size of 28×28 pixels, and that the images are grayscale. Therefore, we can load the images and reshape the data arrays to have a single color channel.","metadata":{}},{"cell_type":"code","source":"training_file = '../input/fashionmnist/fashion-mnist_train.csv'\ntesting_file = '../input/fashionmnist/fashion-mnist_test.csv'\ntrain_data = pd.read_csv(training_file)\ntest_data = pd.read_csv(testing_file)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-02T08:39:34.669645Z","iopub.execute_input":"2021-11-02T08:39:34.6704Z","iopub.status.idle":"2021-11-02T08:39:40.319294Z","shell.execute_reply.started":"2021-11-02T08:39:34.67035Z","shell.execute_reply":"2021-11-02T08:39:40.31692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-02T08:39:40.322884Z","iopub.execute_input":"2021-11-02T08:39:40.323619Z","iopub.status.idle":"2021-11-02T08:39:40.374454Z","shell.execute_reply.started":"2021-11-02T08:39:40.32357Z","shell.execute_reply":"2021-11-02T08:39:40.373309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-02T08:39:40.380156Z","iopub.execute_input":"2021-11-02T08:39:40.38536Z","iopub.status.idle":"2021-11-02T08:39:40.416821Z","shell.execute_reply.started":"2021-11-02T08:39:40.381323Z","shell.execute_reply":"2021-11-02T08:39:40.415591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalize the data\n\nA good starting point is to normalize the pixel values of grayscale images, e.g. rescale them to the range [0,1]. This involves first converting the data type from unsigned integers to floats, then dividing the pixel values by the maximum value.","metadata":{}},{"cell_type":"code","source":"train_data = np.array(train_data, dtype = 'float32')\ntest_data = np.array(test_data, dtype='float32')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-02T08:39:40.420094Z","iopub.execute_input":"2021-11-02T08:39:40.420597Z","iopub.status.idle":"2021-11-02T08:39:40.647746Z","shell.execute_reply.started":"2021-11-02T08:39:40.42055Z","shell.execute_reply":"2021-11-02T08:39:40.646446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = train_data[:,1:]/255\n\ny_train = train_data[:,0]\n\nx_test= test_data[:,1:]/255\n\ny_test=test_data[:,0]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-02T08:39:40.649733Z","iopub.execute_input":"2021-11-02T08:39:40.65006Z","iopub.status.idle":"2021-11-02T08:39:40.74256Z","shell.execute_reply.started":"2021-11-02T08:39:40.650013Z","shell.execute_reply":"2021-11-02T08:39:40.741535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train,x_validate,y_train,y_validate = train_test_split(x_train,y_train,test_size = 0.2,random_state = 12345)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-02T08:39:40.748135Z","iopub.execute_input":"2021-11-02T08:39:40.749909Z","iopub.status.idle":"2021-11-02T08:39:41.296632Z","shell.execute_reply.started":"2021-11-02T08:39:40.749862Z","shell.execute_reply":"2021-11-02T08:39:41.295605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let us visualise the some samples after the resize of the data which needs to be ready for train the network .","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nfor i in range(27):\n    plt.subplot(3, 9, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(x_train[i].reshape((28,28)))\n    plt.title(y_train[i])\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-02T08:39:41.298506Z","iopub.execute_input":"2021-11-02T08:39:41.298844Z","iopub.status.idle":"2021-11-02T08:39:42.985392Z","shell.execute_reply.started":"2021-11-02T08:39:41.2988Z","shell.execute_reply":"2021-11-02T08:39:42.984407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Labels Each training and test example is assigned to one of the following labels as shown below:\n\n- 0 T-shirt/top\n- 1 Trouser\n- 2 Pullover\n- 3 Dress\n- 4 Coat\n- 5 Sandal\n- 6 Shirt\n- 7 Sneaker\n- 8 Bag\n- 9 Ankle boot","metadata":{}},{"cell_type":"code","source":"classification_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\nplt.figure(figsize=(20, 10))\nfor i in range(27):\n    plt.subplot(3, 9, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(x_train[i].reshape((28,28)))\n    label_index = int(y_train[i])\n    plt.title(classification_names[label_index])\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-02T08:39:42.987349Z","iopub.execute_input":"2021-11-02T08:39:42.987967Z","iopub.status.idle":"2021-11-02T08:39:44.397798Z","shell.execute_reply.started":"2021-11-02T08:39:42.98792Z","shell.execute_reply":"2021-11-02T08:39:44.396583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = x_train.reshape(x_train.shape[0],*(28,28,1))\nx_test = x_test.reshape(x_test.shape[0],*(28,28,1))\nx_validate = x_validate.reshape(x_validate.shape[0],*(28,28,1))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-02T08:39:44.39982Z","iopub.execute_input":"2021-11-02T08:39:44.400159Z","iopub.status.idle":"2021-11-02T08:39:44.407253Z","shell.execute_reply.started":"2021-11-02T08:39:44.400109Z","shell.execute_reply":"2021-11-02T08:39:44.406017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Model\n\nNext, we need to define a baseline convolutional neural network model for the problem.\n\nThe model has two main aspects: the feature extraction front end comprised of convolutional and pooling layers, and the classifier backend that will make a prediction.\n\nFor the convolutional front-end, we can start with a single convolutional layer with a small filter size (3,3) and a modest number of filters (32) followed by a max pooling layer. The filter maps can then be flattened to provide features to the classifier.","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10,activation = 'softmax') \n])","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-11-02T08:39:44.4473Z","iopub.status.idle":"2021-11-02T08:39:44.447694Z","shell.execute_reply.started":"2021-11-02T08:39:44.447487Z","shell.execute_reply":"2021-11-02T08:39:44.447516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001),metrics =['accuracy'])","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-11-02T08:39:44.449786Z","iopub.status.idle":"2021-11-02T08:39:44.450962Z","shell.execute_reply.started":"2021-11-02T08:39:44.450568Z","shell.execute_reply":"2021-11-02T08:39:44.450617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate Model","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    x_train,\n    y_train,\n    batch_size=1000,\n    epochs=30,\n    verbose=1,\n    validation_data=(x_validate,y_validate),\n)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-11-02T08:39:44.452386Z","iopub.status.idle":"2021-11-02T08:39:44.453826Z","shell.execute_reply.started":"2021-11-02T08:39:44.453421Z","shell.execute_reply":"2021-11-02T08:39:44.453458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let us plot the Training Accuracy vs Loss to get a better understanding of the model training.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\n\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'],color='blue', label='Loss')\nplt.plot(history.history['val_loss'],color='orange', label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function / Cross Entropy Loss')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'],color='blue', label='Accuracy')\nplt.plot(history.history['val_accuracy'],color='orange', label='Validation Accuracy')\nplt.legend()\nplt.title('Train - Accuracy / Classification Accuracy')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-02T08:39:44.455306Z","iopub.status.idle":"2021-11-02T08:39:44.456546Z","shell.execute_reply.started":"2021-11-02T08:39:44.456167Z","shell.execute_reply":"2021-11-02T08:39:44.456228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(x_test,y_test,verbose=0)\nprint('Test Loss : {:.4f}'.format(score[0]))\nprint('Test Accuracy : {:.4f}'.format(score[1]))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-02T08:39:44.458233Z","iopub.status.idle":"2021-11-02T08:39:44.459227Z","shell.execute_reply.started":"2021-11-02T08:39:44.458885Z","shell.execute_reply":"2021-11-02T08:39:44.458919Z"},"trusted":true},"execution_count":null,"outputs":[]}]}